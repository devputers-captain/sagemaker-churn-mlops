{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5d7be-13be-40c1-a261-d21ced371ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3\n",
    "# !pip install pandas\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608d76a4-00ee-40a8-b9be-0bc7d480e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n============================================================================\\nCOMPLETE AWS SAGEMAKER PIPELINE - CUSTOMER CHURN PREDICTION\\n============================================================================\\nReal-life scenario: A telecom company wants to predict which customers \\nwill cancel their subscription (churn). The pipeline automatically:\\n1. Preprocesses customer data daily\\n2. Trains a model to predict churn\\n3. Evaluates model performance\\n4. Registers the model if it performs well\\n\\nThis runs automatically every night to keep predictions fresh.\\n============================================================================\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "COMPLETE AWS SAGEMAKER PIPELINE - CUSTOMER CHURN PREDICTION\n",
    "============================================================================\n",
    "Real-life scenario: A telecom company wants to predict which customers \n",
    "will cancel their subscription (churn). The pipeline automatically:\n",
    "1. Preprocesses customer data daily\n",
    "2. Trains a model to predict churn\n",
    "3. Evaluates model performance\n",
    "4. Registers the model if it performs well\n",
    "\n",
    "This runs automatically every night to keep predictions fresh.\n",
    "============================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79124f8b-7045-491d-b2e3-a1dd3473ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker import get_execution_role, Session\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184fc921-e5d2-41c0-9967-33e85c599171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Region: ap-south-1\n",
      "INFO:__main__:Role: arn:aws:iam::542810186858:role/service-role/AmazonSageMaker-ExecutionRole-20251230T121523\n",
      "INFO:__main__:Default bucket: sagemaker-ap-south-1-542810186858\n"
     ]
    }
   ],
   "source": [
    "# Setup logging to track pipeline execution\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Get AWS resources\n",
    "sagemaker_session = Session()\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()  # IAM role with SageMaker permissions\n",
    "default_bucket = sagemaker_session.default_bucket()  # S3 bucket for storing data\n",
    "\n",
    "logger.info(f\"Region: {region}\")\n",
    "logger.info(f\"Role: {role}\")\n",
    "logger.info(f\"Default bucket: {default_bucket}\")\n",
    "\n",
    "# Define S3 paths for data storage\n",
    "base_path = f\"s3://{default_bucket}/churn-pipeline\"\n",
    "input_data_path = f\"{base_path}/input-data\"\n",
    "output_data_path = f\"{base_path}/output-data\"\n",
    "model_path = f\"{base_path}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3a629d-a4de-4d62-aea4-afc34628896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pipeline parameters configured\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PIPELINE PARAMETERS - Can be changed at runtime without code changes\n",
    "# ============================================================================\n",
    "\n",
    "# Input data location (can be updated for new data batches)\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"{input_data_path}/customer_data.csv\"\n",
    ")\n",
    "\n",
    "# Instance type for processing (can scale up/down based on data size)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "# Instance type for training\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "# Minimum accuracy threshold for model deployment\n",
    "# Only models with accuracy >= this value will be registered\n",
    "model_approval_threshold = ParameterFloat(\n",
    "    name=\"ModelApprovalThreshold\",\n",
    "    default_value=0.75  # 75% accuracy minimum\n",
    ")\n",
    "\n",
    "logger.info(\"Pipeline parameters configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a6bdd-ccfa-483e-9cb0-509302286ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuring preprocessing step...\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:__main__:Preprocessing step configured\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "# This step cleans raw data, handles missing values, encodes categories,\n",
    "# and splits into train/test sets\n",
    "\n",
    "logger.info(\"Configuring preprocessing step...\")\n",
    "\n",
    "# Create processor instance - this defines the compute resources\n",
    "preprocessing_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",  # Scikit-learn version\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,  # Number of instances (can scale for large data)\n",
    "    base_job_name=\"churn-preprocessing\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Define the preprocessing step\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"PreprocessCustomerData\",  # Step name shown in SageMaker UI\n",
    "    processor=preprocessing_processor,\n",
    "    \n",
    "    # Path to preprocessing script\n",
    "    code=\"src/preprocessing.py\",\n",
    "    \n",
    "    # Input: Raw customer data from S3\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination=\"/opt/ml/processing/input\",  # Where data lands in container\n",
    "            input_name=\"raw_data\"\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    # Outputs: Processed train and test datasets\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",  # Where script saves train data\n",
    "            destination=f\"{output_data_path}/train\"  # S3 destination\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=f\"{output_data_path}/test\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=f\"{output_data_path}/validation\"\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    # Job configuration\n",
    "    job_arguments=[\"--train-split\", \"0.7\", \"--test-split\", \"0.2\"]  # 70-20-10 split\n",
    ")\n",
    "\n",
    "logger.info(\"Preprocessing step configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8662d2-4d38-4f71-a406-f937087f9275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuring training step...\n",
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:__main__:Training step configured\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: MODEL TRAINING\n",
    "# ============================================================================\n",
    "# This step trains a Random Forest model on the preprocessed data\n",
    "\n",
    "logger.info(\"Configuring training step...\")\n",
    "\n",
    "# Create estimator for training\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"training.py\",\n",
    "    source_dir=\"src\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,  # Where trained model is saved\n",
    "    base_job_name=\"churn-training\",\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,      # Number of trees in Random Forest\n",
    "        \"max_depth\": 10,          # Tree depth\n",
    "        \"min_samples_split\": 4    # Minimum samples to split node\n",
    "    },\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Define training step\n",
    "training_step = TrainingStep(\n",
    "    name=\"TrainChurnModelV2\",\n",
    "    estimator=sklearn_estimator,\n",
    "    \n",
    "    # Use output from preprocessing step as training input\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(\"Training step configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2531c7-1538-4698-8af9-929b45db7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuring evaluation step...\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:__main__:Evaluation step configured\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "# This step evaluates model performance on test data\n",
    "\n",
    "logger.info(\"Configuring evaluation step...\")\n",
    "\n",
    "# Create processor for evaluation\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"churn-evaluation\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Define evaluation metrics output location\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ChurnEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"  # Script will create this JSON file\n",
    ")\n",
    "\n",
    "# Define evaluation step\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    code=\"src/evaluation.py\",  # Evaluation script\n",
    "    \n",
    "    inputs=[\n",
    "        # Test data for evaluation\n",
    "        ProcessingInput(\n",
    "            source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        ),\n",
    "        # Trained model artifact\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=f\"{output_data_path}/evaluation\"\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    property_files=[evaluation_report]  # Makes metrics available to next steps\n",
    ")\n",
    "\n",
    "logger.info(\"Evaluation step configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0ff97-b13d-4cbe-98b3-b85e9e4539e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuring conditional registration...\n",
      "INFO:__main__:Conditional registration configured\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: CONDITIONAL MODEL REGISTRATION\n",
    "# ============================================================================\n",
    "# Only register model if accuracy is above threshold\n",
    "\n",
    "logger.info(\"Configuring conditional registration...\")\n",
    "\n",
    "# Create condition: accuracy >= threshold\n",
    "model_approval_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy\"  # Extract accuracy from evaluation.json\n",
    "    ),\n",
    "    right=model_approval_threshold\n",
    ")\n",
    "\n",
    "MODEL_PACKAGE_GROUP_NAME = \"ChurnModelPackageGroup\"\n",
    "\n",
    "# Create model package for registration\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"{output_data_path}/evaluation/evaluation.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Model registration step (only runs if condition is met)\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "try:\n",
    "    register_step = RegisterModel(\n",
    "        name=\"RegisterChurnModel\",\n",
    "        estimator=sklearn_estimator,\n",
    "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.xlarge\"],\n",
    "        transform_instances=[\"ml.m5.xlarge\"],\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "        approval_status=\"PendingManualApproval\",  # Can be auto-approved if needed\n",
    "        # entry_point=\"inference.py\",\n",
    "        # source_s3_uri=\"s3://my-bucket-5428/src/\",\n",
    "        model_metrics=model_metrics\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.info(f\"Registration failed: {e}\")\n",
    "    logger.info(f\"Check ModelPackageGroup: {MODEL_PACKAGE_GROUP_NAME}\")\n",
    "    raise\n",
    "\n",
    "# Conditional step: register only if accuracy is good\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckModelAccuracy\",\n",
    "    conditions=[model_approval_condition],\n",
    "    if_steps=[register_step],  # Register if condition true\n",
    "    else_steps=[]  # Do nothing if condition false\n",
    ")\n",
    "\n",
    "logger.info(\"Conditional registration configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e763b08-b3f7-4eca-8a66-e26095a291f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating pipeline...\n",
      "INFO:__main__:Upserting pipeline...\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:__main__:Pipeline created/updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE AND EXECUTE PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Creating pipeline...\")\n",
    "\n",
    "# Assemble all steps into pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"CustomerChurnPredictionPipelineV2\",\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_threshold\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        training_step,\n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Create or update pipeline in SageMaker\n",
    "logger.info(\"Upserting pipeline...\")\n",
    "pipeline.upsert(role_arn=role)\n",
    "logger.info(\"Pipeline created/updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd9fa33-5ae9-420a-bf51-b9db09abc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting pipeline execution...\n",
      "INFO:__main__:Pipeline execution started: arn:aws:sagemaker:ap-south-1:542810186858:pipeline/CustomerChurnPredictionPipelineV2/execution/ilczan7529ic\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Starting pipeline execution...\")\n",
    "execution = pipeline.start()\n",
    "logger.info(f\"Pipeline execution started: {execution.arn}\")\n",
    "# logger.info(f\"View execution in console: https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/pipelines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a176fb-c8eb-4572-a687-4ed3bbd450c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for completion (optional - remove for async execution)\n",
    "# execution.wait(delay=30, max_attempts=60)\n",
    "# logger.info(f\"Pipeline execution completed with status: {execution.describe()['PipelineExecutionStatus']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9ad41-7ddf-43bd-94f4-9a81f229d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCHEDULE AUTOMATIC RUNS\n",
    "# ============================================================================\n",
    "\n",
    "def schedule_daily_pipeline_run():\n",
    "    \"\"\"\n",
    "    Schedule pipeline to run automatically every day at 2 AM UTC\n",
    "    using AWS EventBridge (CloudWatch Events)\n",
    "    \"\"\"\n",
    "    events_client = boto3.client('events', region_name=region)\n",
    "    \n",
    "    rule_name = 'DailyChurnPipelineRun'\n",
    "    \n",
    "    logger.info(f\"Creating EventBridge rule: {rule_name}\")\n",
    "    \n",
    "    # Create rule to trigger daily\n",
    "    events_client.put_rule(\n",
    "        Name=rule_name,\n",
    "        Description='Trigger churn prediction pipeline daily',\n",
    "        ScheduleExpression='cron(0 2 * * ? *)',  # 2 AM UTC daily\n",
    "        State='ENABLED'\n",
    "    )\n",
    "    \n",
    "    # Get AWS account ID\n",
    "    sts_client = boto3.client('sts')\n",
    "    account_id = sts_client.get_caller_identity()['Account']\n",
    "    \n",
    "    # Add pipeline as target\n",
    "    events_client.put_targets(\n",
    "        Rule=rule_name,\n",
    "        Targets=[\n",
    "            {\n",
    "                'Id': '1',\n",
    "                'Arn': f'arn:aws:sagemaker:{region}:{account_id}:pipeline/CustomerChurnPredictionPipeline',\n",
    "                'RoleArn': role,\n",
    "                'SageMakerPipelineParameters': {\n",
    "                    'PipelineParameterList': [\n",
    "                        {\n",
    "                            'Name': 'InputDataUrl',\n",
    "                            'Value': f'{input_data_path}/customer_data.csv'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Pipeline scheduled to run daily at 2 AM UTC\")\n",
    "    logger.info(f\"Rule ARN: arn:aws:events:{region}:{account_id}:rule/{rule_name}\")\n",
    "\n",
    "# Uncomment to schedule automatic runs:\n",
    "# schedule_daily_pipeline_run()\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def list_pipeline_executions():\n",
    "    \"\"\"List recent pipeline executions\"\"\"\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    response = sm_client.list_pipeline_executions(\n",
    "        PipelineName='CustomerChurnPredictionPipeline',\n",
    "        MaxResults=10\n",
    "    )\n",
    "    for execution in response['PipelineExecutionSummaries']:\n",
    "        print(f\"Execution: {execution['PipelineExecutionArn']}\")\n",
    "        print(f\"Status: {execution['PipelineExecutionStatus']}\")\n",
    "        print(f\"Start Time: {execution['StartTime']}\")\n",
    "        print(\"---\")\n",
    "\n",
    "def stop_pipeline_execution(execution_arn):\n",
    "    \"\"\"Stop a running pipeline execution\"\"\"\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    sm_client.stop_pipeline_execution(PipelineExecutionArn=execution_arn)\n",
    "    logger.info(f\"Stopped execution: {execution_arn}\")\n",
    "\n",
    "# Example usage:\n",
    "# list_pipeline_executions()\n",
    "# stop_pipeline_execution(\"arn:aws:sagemaker:...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
