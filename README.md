# ğŸš€ End-to-End Churn Prediction MLOps Pipeline on AWS SageMaker

This project demonstrates a **production-grade MLOps workflow** using **AWS SageMaker**, focused on training, validating, registering, and deploying a customer churn prediction model.

The goal is to show how **existing ML code** can be **operationalized** using SageMaker Pipelines, Model Registry, and real-time inference endpoints.

---

## ğŸ§  Problem Statement

Customer churn is a critical business problem.  
This project builds an automated ML pipeline that:

- Preprocesses customer data
- Trains a churn prediction model
- Evaluates model quality
- Prevents low-quality models from deploying
- Deploys approved models to a real-time endpoint
- Supports monitoring and retraining

---

## ğŸ—ï¸ Architecture Overview

```

S3 (Input Data)
â†“
ProcessingStep (Preprocessing)
â†“
TrainingStep (Model Training)
â†“
ProcessingStep (Evaluation)
â†“
ConditionStep (Quality Gate)
â†“
Model Registry
â†“
Approved Model
â†“
Real-Time Endpoint

```

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **AWS SageMaker**
  - SageMaker Pipelines
  - Training Jobs
  - Processing Jobs
  - Model Registry
  - Real-time Endpoints
- **scikit-learn**
- **Amazon S3**
- **Amazon CloudWatch**
- **GitHub**

---

## ğŸ“ Repository Structure

```text
sagemaker-churn-mlops/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ customer_data.csv       # Sample input dataset
â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing logic
â”‚   â”œâ”€â”€ training.py             # Model training script
â”‚   â”œâ”€â”€ evaluation.py           # Model evaluation script
â”‚   â””â”€â”€ inference.py            # Inference interface for deployment
â”œâ”€â”€ pipeline.ipynb              # SageMaker Pipeline execution notebook
â”œâ”€â”€ pipeline-visual.md          # Pipeline architecture visualization
â”œâ”€â”€ deploy-with-inference.py    # Model deployment script
â”œâ”€â”€ deploy-model-readme.md      # Deployment instructions
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test-predictions.py     # Endpoint inference tests
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ check-endpoint-logs.py  # CloudWatch log inspection
â”‚   â”œâ”€â”€ cleanup-sagemaker.py    # Resource cleanup utility
â”‚   â””â”€â”€ lambda-function.py      # Optional serverless integration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
---

## âš™ï¸ Pipeline Steps Explained

### 1ï¸âƒ£ Preprocessing
- Cleans and prepares raw data
- Outputs processed training data

### 2ï¸âƒ£ Training
- Trains a scikit-learn churn prediction model
- Saves model artifact to S3

### 3ï¸âƒ£ Evaluation
- Evaluates model performance (e.g., accuracy)
- Writes metrics to `evaluation.json`

### 4ï¸âƒ£ Quality Gate
- Uses a `ConditionStep`
- Only allows models with acceptable metrics to proceed

### 5ï¸âƒ£ Model Registration
- Registers approved models in SageMaker Model Registry
- Enables versioning and governance

---

## ğŸš€ How to Run the Pipeline

### Prerequisites
- AWS account
- SageMaker Notebook or Studio
- IAM role with SageMaker permissions

---

### Step 1ï¸âƒ£ Clone the Repository in SageMaker Notebook

```bash
git clone https://github.com/devputers-captain/sagemaker-churn-mlops.git
cd sagemaker-churn-mlops
````

---

### Step 2ï¸âƒ£ Install Dependencies

```bash
!pip install -r requirements.txt
```

---

### Step 3ï¸âƒ£ Run the Pipeline

- Open and run the `pipeline.ipynb` notebook.
- The notebook loads the pipeline definition and executes it, creating the end-to-end SageMaker Pipeline.

---

### Step 4ï¸âƒ£ Monitor Execution

In AWS Console:

```
SageMaker â†’ Pipelines â†’ ChurnPipeline
```

---

## ğŸ”® Inference

The deployed model exposes a **real-time endpoint** that accepts JSON input:

```json
{
  "gender_male": 1,
  "age": 45,
  "monthly_charges": 29.85,
  "total_charges": 1500.5,
  "tenure": 50,
  "contract_month_to_month": 0,
  "contract_two_year": 1,
  "internet_dsl": 1,
  "tech_support_yes": 1,
  "streaming_tv_yes": 0,
  "payment_electronic_check": 0
}
```

Response:

```json
{
  "churn_probability": 0.03,
  "prediction": "no_churn",
  "risk_level": "low"
}
```
---

## Model Deployment

For deploying the trained model as a real-time endpoint, refer to the `deploy-model-readme.md` file.

