# ğŸš€ End-to-End Churn Prediction MLOps Pipeline on AWS SageMaker

This project demonstrates a **production-grade MLOps workflow** using **AWS SageMaker**, focused on training, validating, registering, and deploying a customer churn prediction model.

The goal is to show how **existing ML code** can be **operationalized** using SageMaker Pipelines, Model Registry, and real-time inference endpoints.

---

## ğŸ§  Problem Statement

Customer churn is a critical business problem.  
This project builds an automated ML pipeline that:

- Preprocesses customer data
- Trains a churn prediction model
- Evaluates model quality
- Prevents low-quality models from deploying
- Deploys approved models to a real-time endpoint
- Supports monitoring and retraining

---

## ğŸ—ï¸ Architecture Overview

```

S3 (Input Data)
â†“
ProcessingStep (Preprocessing)
â†“
TrainingStep (Model Training)
â†“
ProcessingStep (Evaluation)
â†“
ConditionStep (Quality Gate)
â†“
Model Registry
â†“
Approved Model
â†“
Real-Time Endpoint

```

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **AWS SageMaker**
  - SageMaker Pipelines
  - Training Jobs
  - Processing Jobs
  - Model Registry
  - Real-time Endpoints
- **scikit-learn**
- **Amazon S3**
- **Amazon CloudWatch**
- **GitHub**

---

## ğŸ“ Repository Structure

```

sagemaker-churn-mlops/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py      # Data preprocessing
â”‚   â”œâ”€â”€ train.py           # Model training
â”‚   â”œâ”€â”€ evaluate.py        # Model evaluation
â”‚   â””â”€â”€ inference.py       # Inference interface
â”œâ”€â”€ pipeline.py/ipynd      # SageMaker Pipeline definition
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Pipeline Steps Explained

### 1ï¸âƒ£ Preprocessing
- Cleans and prepares raw data
- Outputs processed training data

### 2ï¸âƒ£ Training
- Trains a scikit-learn churn prediction model
- Saves model artifact to S3

### 3ï¸âƒ£ Evaluation
- Evaluates model performance (e.g., accuracy)
- Writes metrics to `evaluation.json`

### 4ï¸âƒ£ Quality Gate
- Uses a `ConditionStep`
- Only allows models with acceptable metrics to proceed

### 5ï¸âƒ£ Model Registration
- Registers approved models in SageMaker Model Registry
- Enables versioning and governance

---

## ğŸš€ How to Run the Pipeline

### Prerequisites
- AWS account
- SageMaker Notebook or Studio
- IAM role with SageMaker permissions

---

### Step 1ï¸âƒ£ Clone the Repository in SageMaker Notebook

```bash
git clone https://github.com/devputers-captain/sagemaker-churn-mlops.git
cd sagemaker-churn-mlops
````

---

### Step 2ï¸âƒ£ Install Dependencies

```bash
!pip install -r requirements.txt
```

---

### Step 3ï¸âƒ£ Run the Pipeline

```python
from pipeline import pipeline
import sagemaker

role = sagemaker.get_execution_role()

pipeline.upsert(role_arn=role)
execution = pipeline.start()
```

---

### Step 4ï¸âƒ£ Monitor Execution

In AWS Console:

```
SageMaker â†’ Pipelines â†’ ChurnPipeline
```

---

## ğŸ”® Inference

The deployed model exposes a **real-time endpoint** that accepts JSON input:

```json
{
  "gender_male": 1,
  "age": 45,
  "monthly_charges": 29.85,
  "total_charges": 1500.5,
  "tenure": 50,
  "contract_month_to_month": 0,
  "contract_two_year": 1,
  "internet_dsl": 1,
  "tech_support_yes": 1,
  "streaming_tv_yes": 0,
  "payment_electronic_check": 0
}
```

Response:

```json
{
  "churn_probability": 0.03,
  "prediction": "no_churn",
  "risk_level": "low"
}
```
---

## ğŸ“Œ Future Enhancements

* Add SageMaker Model Monitor for drift detection
* Automate retraining
* CI/CD integration using GitHub Actions or CodePipeline
* Add SHAP-based model explainability

